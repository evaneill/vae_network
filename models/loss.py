
import torch
import torch.nn as nn
import torch.nn.functional as F

import numpy as np

from torch import Tensor as T
import torch

def VRBound(alpha,model,q_samples,q_mu, q_log_sigmasq,optimize_on='full_lowerbound'):
		""" Monte-carlo estimate of variational renyi bound
		Args:
		    alpha (float): alpha of renyi alpha-divergence
		    model (VRalphaNet): net from models.network
		    q_samples (list): list of the output latent samples form training, with the data as the first element.
		    	(should be the result of model.forward(data))
		    q_mu (list): 
		    q_log_sigmasq (list): resulting log_sigmasq output list of network forward() method - describes 
		    optimize_on (str, optional): Whether to optimize the estimate over all samples, or just the max
		
		"""
		# alpha = torch.float(alpha)

		prior_mu = torch.zeros_like(q_samples[-1]) # Prior is N(0,1) latent distribution in the ultimate encoder layer
		prior_log_sigmasq = torch.zeros_like(q_samples[-1]) # To work with innard of the LL function just use log(sigma^2) instead of sigma

		log_pq_ratio=gaussian_log_likelihood(q_samples[-1],(prior_mu,prior_log_sigmasq))

		for current_sample, next_sample, qmu , qlog_sigmasq, p_layer in zip(q_samples,q_samples[1:],q_mu,q_log_sigmasq,model.decoder.layers[::-1]):
			p_out = next_sample
			for unit in p_layer:
				p_out, pmu, plog_sigmasq = unit.forward(p_out)
			
			if plog_sigmasq is not None:
				# then this unit is a stochastic decoder layer. want LL p(h_i | h_(i+1)) - LL q(h_(i+1) | h(i))
				log_pq_ratio+=gaussian_log_likelihood(current_sample,(pmu,plog_sigmasq)) - gaussian_log_likelihood(next_sample,(qmu,qlog_sigmasq))
			elif pmu is not None and plog_sigmasq is None:
				# then pmu is actually theta of a bernoulli distribution
				log_pq_ratio+=bernoulli_log_likelihood(current_sample,pmu) - gaussian_log_likelihood(next_sample,(qmu,qlog_sigmasq))

		if abs(alpha-1)<=1e-3:
			if optimize_on=='full_lowerbound':
				return torch.mean(log_pq_ratio)
			elif optimize_on=='max':
				log_pq_ratio = log_pq_ratio.reshape([model.encoder.num_samples,-1])
				max_log_ratio_values = log_pq_ratio.max(axis=1)
				return torch.mean(max_log_ratio_values)
			elif optimize_on=='sample':
				#nah
				pass
		else:
			# Trick comes from vae_renyi_divergence codebase, which is is at least from original iwae codebase
			log_pq_ratio_alpha = (1-alpha)*log_pq_ratio.reshape([-1,model.encoder.num_samples])
			max_log_ratio_values = log_pq_ratio.max(axis=1)
			log_pq_ratio_alpha_norm = torch.log(
				torch.sum(
					torch.exp(
						log_pq_ratio_alpha-max_log_ratio_values.values.repeat_interleave(model.encoder.num_samples).reshape([-1,model.encoder.num_samples])
					)
					,axis=1)
				)
			
			if optimize_on=='full_lowerbound':
				tf.reduce_mean(logF_normalizer + logF_max - tf.log(model.encoder.num_samples)) / (1 - alpha)
				return torch.mean(log_pq_ratio_alpha_norm + max_log_ratio_values.values - torch.log(model.encoder.num_samples))/(1-alpha)
			elif optimize_on=='max':
				return torch.mean(max_log_ratio_values.values)
			elif optimize_on=='sample':
				#nah
				pass
			



def gaussian_log_likelihood(sample,params):
	"""Calculate likelihood of current sample given previous (for encoder likelihood, talking about q(h_i | h_(i-1)))
	By switching sample position can just as easily be used for decoder (which would be p(h_(i-1) | h_i), since p operates forward in decreasing latent layers)
	
	Args:
	    sample: that generated by the network (or is just input!) whose likelihood we want to evaluate
	    params (tuple): mu and log_sigmasq generated by network given previous stochastic layer sample output
	
	
	Returns:
	    torch.Tensor: observation-length vector whose entries are Log Likelihood of sample given params
	"""
	(mu, log_sigmasq) = params

	sigma_sq = torch.exp(log_sigmasq)
	output =  -.5*T.log(torch.tensor(2*np.pi)) - .5*log_sigmasq
	output -= .5*T.pow((sample-mu),2)/sigma_sq

	return torch.sum(output,axis=1)

def bernoulli_log_likelihood(sample,theta):
	"""Calculate likelihood of current sample given previous (for encoder likelihood, talking about q(h_i | h_(i-1)))
	By switching sample position can just as easily be used for decoder (which would be p(h_(i-1) | h_i), since p operates forward in decreasing latent layers)
	
	Args:
	    sample: that generated by the network (or is just input!) whose likelihood we want to evaluate
	    theta (Tensor): output distribution-parametrizing 
	
	
	Returns:
	    torch.Tensor: observation-length vector whose entries are Log Likelihood of sample given params
	"""

	output = (1-sample)*(1-theta) + sample*theta

	return torch.sum(output,axis=1)

